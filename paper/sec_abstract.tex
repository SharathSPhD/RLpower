\begin{abstract}
This paper presents \textbf{sCO2RL}, an end-to-end deep reinforcement learning
(RL) framework for autonomous control of a \emph{supercritical CO$_2$ (sCO$_2$)
recuperated Brayton cycle} recovering waste heat from steel industry electric-arc
furnace (EAF) and basic-oxygen furnace (BOF) exhaust (200--1{,}200\textdegree{}C).
The framework integrates a physics-faithful FMI~2.0 Co-Simulation model (FMU)
compiled with OpenModelica, a Gymnasium environment with a seven-phase structured
curriculum, Proximal Policy Optimisation (PPO) with trainable Lagrangian constraint
multipliers for safe operation near the CO$_2$ critical point (31.1\textdegree{}C,
7.38~MPa), an MLP step-predictor surrogate (55{,}000{,}000 transitions, val\_loss
$= 5{\times}10^{-6}$) for GPU-accelerated policy training at 250{,}000~steps/s,
a Fourier Neural Operator (FNO) implemented via \textbf{NVIDIA PhysicsNeMo}
for physics-operator surrogate validation ($R^2 = 1.000$), and a TensorRT-FP16
deployment path for sub-millisecond plant-edge inference.

The framework is validated on two training paths.
On the \emph{FMU-direct path} (5{,}013{,}504 steps, 8 parallel FMU workers),
the RL agent outperforms a Ziegler--Nichols-tuned multi-channel PID baseline by
\textbf{+30.3\%, +30.4\%, and +39.0\%} in cumulative episode reward for
Phases~0--2 (steady-state optimisation, $\pm$30\% gradual load following,
and $\pm$10\textdegree{}C ambient disturbance), with \textbf{zero safety
violations} across all 140~evaluation episodes.
On the \emph{MLP surrogate path} (5{,}000{,}000 steps, 1{,}024 GPU-vectorised
environments), PPO training completes in 23~minutes and achieves
\textbf{18.5$\times$ lower net-power tracking error} than the PID baseline
(0.122~MW vs.\ 2.259~MW), enabling rapid policy development prior to FMU
fine-tuning.

The FNO surrogate ($R^2 = 1.000$, 76{,}600 unique Latin Hypercube trajectories)
was found \emph{architecturally incompatible} with step-by-step RL prediction
due to its non-causal sequence-to-sequence training objective; an MLP step
predictor with residual connections resolves this mismatch at sub-1\% state
prediction error.
The deployment path achieves a p99 host latency of \textbf{0.046~ms},
exceeding the 1~ms plant-edge SLA by a factor of $22\times$.

Five non-trivial software engineering defects encountered during development
are documented in detail — covering observation normalisation persistence,
episode boundary detection, reward unit double-scaling, stale disturbance
profiles, and constraint-violation gating — as actionable practitioner guidance
for the Modelica-RL integration community.

To the authors' knowledge, this is the first publicly available framework
combining (i)~an OpenModelica-exported sCO$_2$ FMU, (ii)~structured curriculum
RL with Lagrangian safety constraints, (iii)~an MLP step-predictor surrogate
enabling 250{,}000~steps/s GPU training, (iv)~NVIDIA PhysicsNeMo FNO surrogate
validation ($R^2 = 1.000$), and (v)~a TensorRT plant-edge deployment path.
All code, configurations, and pre-trained artefacts are released at
\url{https://github.com/SharathSPhD/RLpower} under the MIT licence.
\end{abstract}
