{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 \u2014 RL vs PID Policy Evaluation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SharathSPhD/RLpower/blob/main/notebooks/04_policy_evaluation.ipynb)\n",
    "\n",
    "Visualize RL vs PID results across curriculum phases from saved evaluation report artifacts.\n",
    "\n",
    "This notebook runs fully on Google Colab \u2014 no FMU binary is required. Evaluation results are loaded from `data/evaluation_report.json` and `data/cross_validation_212k.json` in the repository.\n",
    "\n",
    "**Key result**: At step 212,992 with all infrastructure bugs fixed, the RL controller achieves a **+17.6%** improvement in cumulative episode reward over the PID baseline (806.6 vs 685.9) in Phase 0 (steady-state optimisation). The agent subsequently traverses all 7 curriculum phases within 229,376 steps, reaching Phase 6 (emergency turbine trip recovery) with mean reward 399.9 and zero constraint violations."
   ],
   "id": "449dee53"
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T15:12:22.937956Z",
     "iopub.status.busy": "2026-02-18T15:12:22.937825Z",
     "iopub.status.idle": "2026-02-18T15:12:23.111146Z",
     "shell.execute_reply": "2026-02-18T15:12:23.109008Z"
    }
   },
   "source": [
    "# \u2500\u2500 Environment Setup (runs on Colab or locally) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "import subprocess, sys, os\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "REPO_URL = \"https://github.com/SharathSPhD/RLpower.git\"\n",
    "REPO_DIR = \"/content/RLpower\" if IN_COLAB else os.environ.get(\"WORKSPACE_DIR\", \"/workspace\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        subprocess.run([\"git\", \"clone\", \"--depth=1\", REPO_URL, REPO_DIR], check=True)\n",
    "    os.chdir(REPO_DIR)\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"matplotlib\", \"numpy\"],\n",
    "        check=True,\n",
    "    )\n",
    "else:\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local/Docker'}\")\n",
    "print(\"Imports OK\")"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "id": "10be1d3f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T15:12:23.114845Z",
     "iopub.status.busy": "2026-02-18T15:12:23.114669Z",
     "iopub.status.idle": "2026-02-18T15:12:23.118455Z",
     "shell.execute_reply": "2026-02-18T15:12:23.117740Z"
    }
   },
   "source": [
    "ROOT = Path('.').resolve()\n",
    "\n",
    "def _load_report(data_path, fallback_path):\n",
    "    p = ROOT / data_path\n",
    "    if not p.exists():\n",
    "        p = ROOT / fallback_path\n",
    "    return json.loads(p.read_text())\n",
    "\n",
    "# Final 5M-step policy, evaluated on all 7 curriculum phases\n",
    "final = _load_report('data/cross_validation_final_5M.json',\n",
    "                     'artifacts/reports/cross_validation_final_5M.json')\n",
    "# Early result: bugs fixed at 212k steps (steady-state only)\n",
    "cv212k = _load_report('data/cross_validation_212k.json',\n",
    "                      'artifacts/reports/cross_validation_cpu_parallel_212k.json')\n",
    "\n",
    "per_phase = final.get('per_phase', [])\n",
    "phases = [p['phase'] for p in per_phase]\n",
    "rl    = np.asarray([p['rl_mean_reward']        for p in per_phase], dtype=np.float64)\n",
    "pid   = np.asarray([p['pid_mean_reward']        for p in per_phase], dtype=np.float64)\n",
    "impr  = np.asarray([p['reward_improvement_pct'] for p in per_phase], dtype=np.float64)\n",
    "\n",
    "PHASE_NAMES = [\n",
    "    'Ph0 Steady-state',\n",
    "    'Ph1 Gradual load',\n",
    "    'Ph2 Ambient disturbance',\n",
    "    'Ph3 EAF transients',\n",
    "    'Ph4 Load rejection',\n",
    "    'Ph5 Cold startup',\n",
    "    'Ph6 Emergency trip',\n",
    "]\n",
    "\n",
    "print('=== Final 5,013,504-step policy (all 7 phases) ===')\n",
    "print(f'{\"Phase\":<25} {\"RL\":>8} {\"PID\":>8} {\"Improvement\":>12} {\"RL viol\":>8}')\n",
    "print('-' * 65)\n",
    "for p in per_phase:\n",
    "    name = PHASE_NAMES[p['phase']]\n",
    "    sign = '+' if p['reward_improvement_pct'] >= 0 else ''\n",
    "    print(f'{name:<25} {p[\"rl_mean_reward\"]:8.1f} {p[\"pid_mean_reward\"]:8.1f} '\n",
    "          f'{sign}{p[\"reward_improvement_pct\"]:10.1f}%  {p[\"rl_violation_rate\"]:7.4f}')\n",
    "print()\n",
    "print(f'Early (212k steps, bugs fixed): RL={cv212k[\"rl_mean_reward\"]:.1f}  '\n",
    "      f'PID={cv212k[\"pid_mean_reward\"]:.1f}  +{cv212k[\"reward_improvement_pct\"]:.1f}%')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Overall RL mean reward: 134.2883293282662\n",
      "Overall PID mean reward: 114.31978125194696\n",
      "Overall improvement %: 17.46727281793542\n"
     ]
    }
   ],
   "id": "fb350175"
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T15:12:23.121364Z",
     "iopub.status.busy": "2026-02-18T15:12:23.121273Z",
     "iopub.status.idle": "2026-02-18T15:12:23.151913Z",
     "shell.execute_reply": "2026-02-18T15:12:23.151192Z"
    }
   },
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "x = np.arange(len(phases))\n",
    "w = 0.35\n",
    "axs[0].bar(x - w/2, rl,  w, label='RL (PPO + Lagrangian, 5M steps)', color='steelblue', alpha=0.85)\n",
    "axs[0].bar(x + w/2, pid, w, label='PID Baseline',                    color='coral',     alpha=0.85)\n",
    "axs[0].set_xticks(x)\n",
    "axs[0].set_xticklabels(PHASE_NAMES, rotation=35, ha='right', fontsize=8)\n",
    "axs[0].set_ylabel('Mean episode reward')\n",
    "axs[0].set_title('Final 5M-step policy: RL vs PID per phase')\n",
    "axs[0].axhline(0, color='k', linewidth=0.5)\n",
    "axs[0].legend()\n",
    "\n",
    "colors = ['#2ecc71' if v >= 0 else '#e74c3c' for v in impr]\n",
    "bars = axs[1].bar(x, impr, color=colors, alpha=0.85)\n",
    "axs[1].axhline(0.0, color='black', linewidth=1)\n",
    "axs[1].axhline(cv212k['reward_improvement_pct'], color='tab:blue', linestyle='--', linewidth=1.5,\n",
    "               label=f'Early 212k step: {cv212k[\"reward_improvement_pct\"]:+.1f}% (steady-state only)')\n",
    "axs[1].set_xticks(x)\n",
    "axs[1].set_xticklabels(PHASE_NAMES, rotation=35, ha='right', fontsize=8)\n",
    "axs[1].set_ylabel('Improvement over PID [%]')\n",
    "axs[1].set_title('RL vs PID improvement per phase\\n(+: RL wins  \u2212: catastrophic forgetting)')\n",
    "axs[1].legend(fontsize=9)\n",
    "axs[1].grid(True, axis='y', alpha=0.4)\n",
    "axs[1].axvspan(2.5, 6.5, alpha=0.07, color='red')\n",
    "axs[1].text(4.5, min(impr) * 0.75, 'Catastrophic forgetting\\n(Ph3-6: <5% of training steps)',\n",
    "            ha='center', fontsize=8, color='darkred', style='italic')\n",
    "for bar, val in zip(bars, impr):\n",
    "    sign = '+' if val >= 0 else ''\n",
    "    ypos = val + 1.5 if val >= 0 else val - 1.5\n",
    "    va = 'bottom' if val >= 0 else 'top'\n",
    "    axs[1].text(bar.get_x() + bar.get_width()/2, ypos, f'{sign}{val:.0f}%',\n",
    "                ha='center', va=va, fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/policy_evaluation.png', dpi=90, bbox_inches='tight')\n",
    "plt.show()\n",
    "print()\n",
    "print('Key: Phases 0-2 (steady-state to ambient disturbance) -> RL wins +24-29%')\n",
    "print('Phases 3-6 (EAF transients to emergency trip)       -> catastrophic forgetting')\n",
    "print('ALL 70 evaluation episodes: zero constraint violations.')\n"
   ],
   "execution_count": 3,
   "outputs": [],
   "id": "dedb720a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}